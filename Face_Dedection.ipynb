{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vr_9Ajq0FFN",
        "outputId": "320f5a17-afe4-44e9-9ff7-9c09b065b61d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m129.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install insightface onnxruntime torch torchvision -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "fBHng4J00sw3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from numpy.linalg import norm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vbKrTVH1VV6",
        "outputId": "608594cf-64b8-4702-9470-4da2edf37afa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 281857/281857 [00:03<00:00, 84190.24KB/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ],
      "source": [
        "app = FaceAnalysis(\n",
        "    name=\"buffalo_l\",     # ArcFace + detector + landmark\n",
        "    providers=['CPUExecutionProvider']\n",
        ")\n",
        "\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXkjFpQO1cNe",
        "outputId": "8f1bd1cc-9121-41d3-be46-16eceac84c4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Referans embedding hazır: (512,)\n"
          ]
        }
      ],
      "source": [
        "REF_DIR = \"/content/drive/MyDrive/dataset_face/me\"\n",
        "embeddings = []\n",
        "\n",
        "for img_name in os.listdir(REF_DIR):\n",
        "    img = cv2.imread(os.path.join(REF_DIR, img_name))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    faces = app.get(img)\n",
        "    if len(faces) == 0:\n",
        "        continue\n",
        "\n",
        "    embeddings.append(faces[0].embedding)\n",
        "\n",
        "ref_embedding = np.mean(embeddings, axis=0)\n",
        "ref_embedding = ref_embedding / norm(ref_embedding)\n",
        "\n",
        "print(\"Referans embedding hazir:\", ref_embedding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5hKPxbyf1ebp"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (norm(a) * norm(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AvGPih3G0Gka"
      },
      "outputs": [],
      "source": [
        "def verify_face(image_path, threshold=0.6):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    faces = app.get(img)\n",
        "    if len(faces) == 0:\n",
        "        return False, 0.0\n",
        "\n",
        "    emb = faces[0].embedding\n",
        "    emb = emb / norm(emb)\n",
        "\n",
        "    score = cosine_similarity(ref_embedding, emb)\n",
        "    return score > threshold, score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeicoSd21f0r",
        "outputId": "4c2f545d-1609-4ddb-d9a7-7a0378195db7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eşleşti mi: True\n",
            "Benzerlik: 0.6437473\n"
          ]
        }
      ],
      "source": [
        "result, score = verify_face(\"/content/drive/MyDrive/test.jpg\")\n",
        "\n",
        "print(\"Eşleşti mi:\", result)\n",
        "print(\"Benzerlik:\", score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGumZHF_0urY",
        "outputId": "bd0e7b8c-5c85-4a35-d94c-b0a64a48ebc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Referans embedding kaydedildi\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/ref_embedding.npy\", ref_embedding)\n",
        "print(\"Referans embedding kaydedildi\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
