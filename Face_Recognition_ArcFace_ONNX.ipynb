{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Embedding Nedir?**\n",
        "\n",
        "# Bu çalışmada, milyonlarca yüzle önceden eğitilmiş güçlü bir derin öğrenme modeli olan ArcFace'i kullanarak yeni bir model eğitmek yerine, yüzünüzü sisteme \"tanıştırma\" (özellik çıkarımı) işlemini gerçekleştiriyoruz. Koleksiyonunuzdaki her bir fotoğrafı modelimizden geçirerek yüzünüzün matematiksel özeti olan 512 boyutlu dijital parmak izlerini (embedding) elde ediyoruz; ardından bu farklı örneklerin ortalamasını alarak ışık veya açı gibi dış etkenlerden arındırılmış, en kararlı referans vektörümüzü oluşturuyoruz. Son aşamada yaptığımız normalizasyon işlemiyle de bu dijital kimliğinizi, C++ tarafında kameradan gelen anlık görüntülerle saniyeler içinde ve yüksek doğrulukla kıyaslanabilecek profesyonel bir veri yapısına dönüştürüyoruz."
      ],
      "metadata": {
        "id": "mREsCR5ax_uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Embedding, bir yüzün matematiksel parmak izidir. Model (ArcFace), karmaşık bir yüz fotoğrafını alıp onu 512 tane sayıdan oluşan bir vektöre dönüştürür. Bu sayılar, yüzündeki karakteristik özellikleri (göz mesafesi, burun yapısı vb.) dijital bir imza haline getirir."
      ],
      "metadata": {
        "id": "XriSP5ghxCCY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neden Sınıflandırma (YOLOv8) Değil de \"Embedding\" Kullanıyoruz?**\n",
        "\n",
        "# YOLOv8 gibi standart sınıflandırma modelleri nesneyi \"etiketlemek\" üzerine kuruludur; bu yüzden sisteme yeni bir kişi eklemek istediğinizde tüm modeli binlerce fotoğraflarla baştan eğitmeniz gerekir. Biz ise ArcFace ile yüzü 512 boyutlu evrensel bir sayısal parmak izine (embedding) dönüştürüyoruz.\n",
        "\n",
        "# Bu yöntem sayesinde modelimizi hiçbir zaman yeniden eğitmeden, sadece matematiksel imzaları kıyaslayarak yeni kişileri saniyeler içinde sisteme tanıtabiliyoruz. Sonuç olarak; hantal eğitim süreçlerinden kurtulmuş, milyonlarca kişiye aynı hızla ölçeklenebilen, esnek ve profesyonel bir dijital kimlik altyapısı inşa ediyoruz."
      ],
      "metadata": {
        "id": "oHfsSHvHzN_2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vr_9Ajq0FFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5dd200d-91c1-4b4a-d50d-07c8644b2e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install insightface onnxruntime torch torchvision -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from numpy.linalg import norm\n",
        "import os"
      ],
      "metadata": {
        "id": "fBHng4J00sw3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bu satırda, sistemin hangi modelleri kullanacağını ve bu modellerin nerede çalışacağını tanımlıyoruz.\n"
      ],
      "metadata": {
        "id": "VPUid0VAwMoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "app = FaceAnalysis(\n",
        "    name=\"buffalo_l\",     # ArcFace + detector + landmark\n",
        "    providers=['CPUExecutionProvider']\n",
        ")\n",
        "# buffalo_l doğrudan ArcFace mimarisini kullanan ve InsightFace kütüphanesi tarafından sunulan en güçlü model paketlerinden biri\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))"
      ],
      "metadata": {
        "id": "2vbKrTVH1VV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5241c0bf-2e73-418c-bbf4-b7bcda83aa0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 281857/281857 [00:03<00:00, 89358.89KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ortalama Almanın Mantığı: Klasörümüzdeki tüm fotoğraflardan ayrı ayrı embedding'ler çıkarıp bunların ortalamasını (np.mean) alıyoruz. Bu sayede farklı ışık, açı veya mimiklerden kaynaklanan hataları temizleyerek, yüzümüzü temsil eden en kararlı ve kusursuz \"referans vektörü\" oluşturuyoruz.\n",
        "\n",
        "#Normalizasyon: En sonda yaptığımız norm işlemi, bu 512 sayıyı \"birim boyuta\" getiriyor. Bu, C++ tarafında anlık gelen yüzle bu referans yüzü karşılaştırırken (Cosine Similarity) hesaplamanın çok daha hızlı ve doğru yapılmasını sağlar."
      ],
      "metadata": {
        "id": "2nw5kmlvxY_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REF_DIR = \"/content/drive/MyDrive/dataset_face/me\"\n",
        "embeddings = []\n",
        "\n",
        "for img_name in os.listdir(REF_DIR):\n",
        "    img = cv2.imread(os.path.join(REF_DIR, img_name))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    faces = app.get(img)\n",
        "    if len(faces) == 0:\n",
        "        continue\n",
        "\n",
        "    embeddings.append(faces[0].embedding)\n",
        "\n",
        "ref_embedding = np.mean(embeddings, axis=0)\n",
        "ref_embedding = ref_embedding / norm(ref_embedding)\n",
        "\n",
        "print(\"Referans embedding hazır:\", ref_embedding.shape)"
      ],
      "metadata": {
        "id": "HXkjFpQO1cNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e854dad-7911-4f28-f888-27e27fee0dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Referans embedding hazır: (512,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tanıma aşamasında, kameradan gelen anlık yüz vektörünüz ile sistemimize daha önce kaydettiğimiz referans vektörünüz arasındaki benzerliği Cosine Similarity (Kosinüs Benzerliği) yöntemiyle ölçüyoruz. Burada odak noktamız noktalar arasındaki düz mesafe değil, bu iki vektör arasındaki \"açısal yakınlıktır.\" Bu yaklaşım sayesinde, ortamdaki ışık şiddeti veya gölge durumu değişse bile yüzünüzün karakteristik yapısı (yani vektörün yönü) değişmediği için sizi her türlü koşulda yüksek doğrulukla ve hızla tanıyabiliyoruz."
      ],
      "metadata": {
        "id": "5SmwFLDmyspH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (norm(a) * norm(b))"
      ],
      "metadata": {
        "id": "5hKPxbyf1ebp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_face(image_path, threshold=0.6):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    faces = app.get(img)\n",
        "    if len(faces) == 0:\n",
        "        return False, 0.0\n",
        "\n",
        "    emb = faces[0].embedding\n",
        "    emb = emb / norm(emb)\n",
        "\n",
        "    score = cosine_similarity(ref_embedding, emb)\n",
        "    return score > threshold, score"
      ],
      "metadata": {
        "id": "AvGPih3G0Gka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result, score = verify_face(\"/content/drive/MyDrive/test.jpg\")\n",
        "\n",
        "print(\"Eşleşti mi:\", result)\n",
        "print(\"Benzerlik:\", score)"
      ],
      "metadata": {
        "id": "QeicoSd21f0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e3d8fad-b564-44a0-b183-55b67b8437df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eşleşti mi: True\n",
            "Benzerlik: 0.6808997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.save(\"my_face.npy\", ref_embedding)\n",
        "print(\"Python için embedding kaydedildi: my_face.npy\")"
      ],
      "metadata": {
        "id": "CeldDVccv78C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bu veriyi C++ projemize doğrudan gömebilmek (hardcoded) için bir header (my_face.h) dosyasına dönüştürdük; bu sayede diskten dosya okuma gecikmesini (I/O lag) tamamen ortadan kaldırdık."
      ],
      "metadata": {
        "id": "HJhk9C_swuRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Embedding'i listeye çeviriyoruz\n",
        "embedding_list = ref_embedding.flatten().tolist()\n",
        "\n",
        "# C++ Header dosyası oluşturma\n",
        "header_content = f\"\"\"#ifndef MY_FACE_H\n",
        "#define MY_FACE_H\n",
        "\n",
        "// Auto-generated embedding vector\n",
        "const float my_face_embedding[512] = {{\n",
        "    {', '.join(map(str, embedding_list))}\n",
        "}};\n",
        "\n",
        "#endif\n",
        "\"\"\"\n",
        "\n",
        "with open(\"my_face.h\", \"w\") as f:\n",
        "    f.write(header_content)\n",
        "\n",
        "print(\"C++ Header dosyası oluşturuldu: my_face.h\")"
      ],
      "metadata": {
        "id": "ZGumZHF_0urY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfccf8b8-4416-49a8-d1e1-ca1ab3e920b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C++ Header dosyası oluşturuldu: my_face.h\n"
          ]
        }
      ]
    }
  ]
}